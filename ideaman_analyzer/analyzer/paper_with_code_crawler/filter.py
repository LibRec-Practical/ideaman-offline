if __name__ == '__main__':
    nlp_words = [
        "model",
        "dataset",
        "task",
        "state art",
        "based",
        "method",
        "using",
        "data",
        "representation",
        "neural network",
        "text",
        "sentence",
        "natural language",
        "word",
        "show",
        "performance",
        "different",
        "two",
        "use",
        "system",
        "approach",
        "document",
        "training",
        "feature",
        "new",
        "graph",
        "embedding",
        "bert",
        "one",
        "problem",
        "information",
        "language model",
        "context",
        "structure",
        "first",
        "topic",
        "result",
        "paper",
        "multiple",
        "existing",
        "architecture",
        "baseline",
        "semantic",
        "domain",
        "present",
        "pre trained",
        "relation",
        "accuracy",
        "work",
        "used",
        "word embedding",
        "demonstrate",
        "framework",
        "deep learning",
        "image",
        "approaches",
        "several",
        "cross lingual",
        "machine translation",
        "better",
        "many",
        "learn",
        "network",
        "layer",
        "propose",
        "human",
        "set",
        "benchmark",
        "corpus",
        "algorithm",
        "evaluation",
        "prediction",
        "input",
        "classification",
        "novel",
        "provide",
        "label",
        "topic model",
        "improve",
        "experiment",
        "well",
        "question answering",
        "text classification",
        "attention",
        "challenge",
        "introduce",
        "question",
        "time",
        "emotion recognition",
        "https github",
        "analysis",
        "lstm",
        "large",
        "achieve",
        "various",
        "knowledge",
        "across",
        "sequence",
        "technique",
        "without",
        "semantic parsing",
        "require",
        "perform",
        "relation extraction",
        "generate",
        "outperform",
        "three",
        "sentiment analysis",
        "emotion",
        "make",
        "single",
        "application",
        "multi",
        "dependency parsing",
        "level",
        "efficient",
        "language processing",
        "answer",
        "paper propose",
        "train",
        "end end",
        "generation",
        "modeling",
        "transformer",
        "improvement",
        "often",
        "evaluate",
        "via",
        "compared",
        "annotation",
        "including",
        "process",
        "study",
        "encoder",
        "standard",
        "effective",
        "specific",
        "named entity",
        "experimental result",
        "important",
        "even",
        "unsupervised",
        "rnn",
        "reading comprehension",
        "target",
        "inference",
        "find",
        "recurrent neural",
        "entity recognition",
        "english",
        "type",
        "parameter",
        "deep",
        "attention mechanism",
        "proposed",
        "source",
        "learned",
        "recent",
        "text summarization",
        "cnn",
        "output",
        "current",
        "order",
        "simple",
        "data augmentation",
        "language inference",
        "score",
        "challenging",
        "span",
        "learning",
        "space",
        "due",
        "multilingual",
        "user",
        "results show",
        "large scale",
        "summarization",
        "way",
        "point",
        "pre training",
        "complex",
        "art performance",
        "encoding",
        "structured",
        "quality",
        "generated",
        "step",
        "sequence sequence",
        "robust",
        "neural machine",
        "improving",
        "parser",
        "token",
        "capture",
        "example",
        "extract",
        "enable",
        "convolutional neural",
        "nlp tasks",
        "summary",
        "produce",
        "designed",
        "content",
        "new state",
        "based model",
        "art result",
        "help",
        "code",
        "among",
        "corpora",
        "syntactic",
        "similar",
        "number",
        "deep neural",
        "propose novel",
        "thus",
        "test",
        "finally",
        "translation",
        "pair",
        "classifier",
        "trained",
        "character",
        "able",
        "setting",
        "available https",
        "text generation",
        "limited",
        "research",
        "common",
        "popular",
        "less",
        "distribution",
        "proposed model",
        "parsing",
        "instead",
        "length",
        "directly",
        "signal",
        "pattern",
        "training data",
        "achieved",
        "vector",
        "much",
        "especially",
        "shown",
        "size",
        "matching",
        "four",
        "instance",
        "hierarchical",
        "sequence model",
        "part speech",
        "machine learning",
        "lingual transfer",
        "traditional",
        "transfer",
        "particular",
        "non",
        "general",
        "recently",
        "within",
        "semantic similarity",
        "experiments show",
        "fine tuning",
        "understanding",
        "pipeline",
        "long",
        "annotated",
        "linguistic",
        "tree",
        "improved",
        "need",
        "consider",
        "learning model",
        "joint",
        "addition",
        "benefit",
        "search",
        "alignment",
        "summaries",
        "given",
        "additional",
        "allow",
        "neural model",
        "information retrieval",
        "paper present",
        "language understanding",
        "visual",
        "design",
        "multimodal",
        "best",
        "high",
        "generalization",
        "lack",
        "contain",
        "publicly available",
        "word vector",
        "multi task",
        "self attention",
        "language modeling",
        "second",
        "case",
        "global",
        "entities",
        "reduce",
        "may",
        "widely used",
        "machine reading",
        "explore",
        "applied",
        "significant",
        "fact",
        "compare",
        "resulting",
        "term",
        "rich",
        "prior",
        "called",
        "robustness",
        "original",
        "part",
        "retrieval",
        "related",
        "table",
        "efficiency",
        "ner",
        "aim",
        "lead",
        "extensive experiments",
        "encoder decoder",
        "evaluated",
        "latent",
        "labeled",
        "reasoning",
        "lexical",
        "unified",
        "form",
        "nlp",
        "still",
        "biomedical",
        "support",
        "position",
        "zero shot",
        "propose new",
        "sequence labeling",
        "specifically",
        "local",
        "useful",
        "moreover",
        "generative",
        "key",
        "usually",
        "aspect",
        "generating",
        "metric",
        "concept",
        "address",
        "bleu",
        "field",
        "take",
        "semantic parser",
        "model achieve",
        "show proposed",
        "classification task",
        "investigate",
        "jointly",
        "combine",
        "apply",
        "furthermore",
        "analyze",
        "memory",
        "interaction",
        "response",
        "module",
        "issue",
        "yield",
        "collection",
        "toward",
        "low resource",
        "pos tagging",
        "possible",
        "detection",
        "obtain",
        "highly",
        "significantly",
        "objective",
        "average",
        "difficult",
        "fast",
        "effectively",
        "strong",
        "competitive",
        "comparison",
        "extend",
        "potential",
        "tool",
        "open domain",
        "trained language",
        "benchmark dataset",
        "language",
        "predict",
        "dialogue",
        "ability",
        "obtained",
        "top",
        "small",
        "conversational",
        "conversation",
        "either",
        "component",
        "temporal",
        "conduct",
        "abstract",
        "sample",
        "leverage",
        "range",
        "strategies",
        "utilize",
        "achieves state",
        "audio",
        "face",
        "ensemble",
        "typically",
        "rely",
        "pretrained",
        "utterance",
        "reader",
        "passage",
        "automatically",
        "vocabulary",
        "measure",
        "increase",
        "consist",
        "proposed method",
        "database",
        "focus",
        "contrast",
        "chinese",
        "build",
        "query",
        "noise",
        "noisy",
        "accurate",
        "function",
        "previous",
        "fully",
        "parallel",
        "weight",
        "studies",
        "gpt",
        "diverse",
        "trained model",
        "knowledge base",
        "real world",
        "develop",
        "constraint",
        "mechanism",
        "extracted",
        "low",
        "dependencies",
        "despite",
        "supervision",
        "program",
        "decoding",
        "selection",
        "scale",
        "contextual",
        "success",
        "solve",
        "respectively",
        "strategy",
        "include",
        "gap",
        "fine grained",
        "resource language",
        "work propose",
        "code available",
        "speech tagging",
        "learning based",
        "word representation",
        "complexity",
        "along",
        "error",
        "goal",
        "nature",
        "meaning",
        "effectiveness",
        "correlation",
        "insight",
        "independent",
        "view",
        "become",
        "direction",
        "incorporating",
        "scenario",
        "generalize",
        "advantage",
        "gain",
        "existing methods",
        "reinforcement learning",
        "wide range",
        "language generation",
        "topic modeling",
        "strong baseline",
        "art method",
        "discrete",
        "hidden",
        "group",
        "higher",
        "correct",
        "linear",
        "demonstrated",
        "six",
        "estimate",
        "amount",
        "version",
        "real",
        "fusion",
        "critical",
        "subword",
        "external",
        "faster",
        "class",
        "pretraining",
        "rule",
        "open source",
        "generative model",
        "social media",
        "recurrent network",
        "word level",
        "paper introduce",
        "representation learning",
        "automatic",
        "comparable",
        "incorporate",
        "map",
        "encode",
        "rather",
        "handle",
        "represent",
        "exploit",
        "sparse",
        "candidate",
        "unlabeled",
        "applying",
        "finding",
        "conventional",
        "powerful",
        "five",
        "comprehensive",
        "good",
        "outperforms state",
        "transition based",
        "long short",
        "short term",
        "semi supervised",
        "language representation",
        "knowledge graph",
        "term memory",
        "solution",
        "auxiliary",
        "combining",
        "shared",
        "individual",
        "major",
        "although",
        "evaluating",
        "computation",
        "provided",
        "combined",
        "literature",
        "entailment",
        "hard",
        "clinical",
        "dynamic",
        "lexicon",
        "alternative",
        "description",
        "relationship",
        "phrase",
        "source code",
        "transfer learning",
        "neural semantic",
        "dependency parser",
        "human evaluation",
        "recognition ner",
        "multi label",
        "convolutional network",
        "generation task",
        "adversarial examples",
        "learning method",
        "extraction",
        "alleviate",
        "continuous",
        "interpretability",
        "squad",
        "create",
        "perspective",
        "sampling",
        "compositional",
        "larger",
        "simultaneously",
        "node",
        "extracting",
        "variant",
        "imagenet",
        "music",
        "million",
        "keyword",
        "event",
        "medical",
        "paragraph",
        "generator",
        "factor",
        "significant improvement",
        "current state",
        "downstream task",
        "sentence pair",
        "sequence modeling",
        "capsule networks",
        "supervised learning",
        "previous work",
        "vector space",
        "practical",
        "loss",
        "supervised",
        "released",
        "modalities",
        "video",
        "sub",
        "segmentation",
        "building",
        "universal",
        "corresponding",
        "showing",
        "containing",
        "construct",
        "next",
        "downstream",
        "reference",
        "effect",
        "making",
        "pose",
        "public",
        "variety",
        "researchers",
        "america",
        "sequential",
        "made",
        "toolkit",
        "full",
        "sensitive",
        "capable",
        "article",
        "employ",
        "speed",
        "attack",
        "online",
        "procedure",
        "synthetic",
        "augmented",
        "gpu",
        "implementation",
        "estimation",
        "characteristic",
        "combination",
        "extension",
        "variation",
        "training set",
        "semantic relevance",
        "significantly improve",
        "sentence embedding",
        "many nlp",
        "labeled data",
        "new dataset",
        "propose simple",
        "supervised training",
        "short text",
        "data set",
        "previously",
        "crucial",
        "value",
        "development",
        "entire",
        "shot",
        "release",
        "pseudo",
        "achieving",
        "evidence",
        "additionally",
        "history",
        "community",
        "yet",
        "report",
        "review",
        "created",
        "fundamental",
        "match",
        "every",
        "integrate",
        "eight",
        "discriminative",
        "mining",
        "namely",
        "exhibit",
        "diversity",
        "statistical",
        "offer",
        "optimizer",
        "implement",
        "relative",
        "agent",
        "optimization",
        "depth",
        "limitation",
        "explanation",
        "transformer based",
        "text corpora",
        "source text",
        "based sentiment",
        "information extraction",
        "recent work",
        "work present",
        "recent years",
        "textual similarity",
        "bert based",
        "significantly outperform",
        "time series",
        "logical form",
        "entities relation",
        "particularly",
        "extensive",
        "identification",
        "amr",
        "properties",
        "employed",
        "similarity",
        "decoder",
        "predicting",
        "aware",
        "adapt",
        "condition",
        "turn",
        "wikipedia",
        "give",
        "technology",
        "promising",
        "efficiently",
        "snli",
        "flexibility",
        "known",
        "ten",
        "optimal",
        "little",
        "crf",
        "formulation",
        "developed",
        "ontology",
        "dnn",
        "parallelism",
        "expert",
        "computational",
        "cost",
        "account",
        "meta",
        "providing",
        "come",
        "unit",
        "training time",
        "meaning representation",
        "improve performance",
        "aspect based",
        "test set",
        "attention based",
        "translation nmt",
        "contextual embedding",
        "tasks including",
        "evaluation metric",
        "show approach",
        "using deep",
        "latent variable",
        "unseen",
        "category",
        "open",
        "tackle",
        "final",
        "currently",
        "transition",
        "rank",
        "produced",
        "facilitate",
        "empirically",
        "capacity",
        "unique",
        "main",
        "analyzing",
        "utilized",
        "utilizing",
        "identify",
        "considered",
        "explicit",
        "extractive",
        "abstractive",
        "automated",
        "leveraging",
        "illustrate",
        "classes",
        "discourse",
        "informative",
        "focused",
        "required",
        "change",
        "guided",
        "vae",
        "suffer",
        "observe",
        "bayesian",
        "expression",
        "head",
        "emotional",
        "read",
        "control",
        "regularization",
        "emotion analysis",
        "networks cnns",
        "paper describe",
        "cross domain",
        "word segmentation",
        "distant supervision",
        "training example",
        "text simplification",
        "textual entailment",
        "three tasks",
        "semantic textual",
        "commonly used",
        "nmt model",
        "semantic information",
        "high level",
        "variational autoencoder",
        "propose two",
        "abstractive summarization",
        "subword segmentation",
        "structured prediction",
        "interesting",
        "augmentation",
        "boost",
        "modality",
        "random",
        "written",
        "underlying",
        "formal",
        "mention",
        "categories",
        "complementary",
        "direct",
        "easy",
        "treebank",
        "empirical",
        "easily",
        "intermediate",
        "representing",
        "encoded",
        "subtask",
        "purpose",
        "tagging",
        "distinct",
        "power",
        "plus",
        "introduced",
        "carefully",
        "series",
        "explicitly",
        "validate",
        "rouge",
        "edge",
        "implemented",
        "manually",
        "variable",
        "discover",
        "frequency",
        "choice",
        "together",
        "fail",
        "bias",
        "play",
        "formalism",
        "confidence",
        "effort",
        "tweet",
        "kind",
        "visual emotion",
        "weakly supervised",
        "search space",
        "learning algorithm",
        "variety tasks",
        "simple yet",
        "recently proposed",
        "introduce new",
        "shared task",
        "adversarial training",
        "plus plus",
        "decoder model",
        "processing nlp",
        "absolute improvement",
        "character level",
        "label text",
        "domain adaptation",
        "loss function",
        "learning framework",
        "pooling operation",
        "processing task",
        "available",
        "performed",
        "suggest",
        "performing",
        "defined",
        "textual",
        "considering",
        "explored",
        "sql",
        "natural",
        "area",
        "bidirectional",
        "subset",
        "increasing",
        "lower",
        "outperforming",
        "simplified",
        "encourage",
        "specialized",
        "future",
        "remain",
        "found",
        "dollar",
        "scoring",
        "ranking",
        "attempt",
        "binary",
        "nli",
        "gradient",
        "interest",
        "far",
        "verify",
        "whether",
        "gram",
        "adding",
        "initial",
        "style",
        "unlike",
        "difficulty",
        "essential",
        "dynamically",
        "constructed",
        "compression",
        "flat",
        "perplexity",
        "asr",
        "advance",
        "enhance",
        "hashing",
        "hardware",
        "potentially",
        "lda",
        "suitable",
        "will",
        "demonstrating",
        "exploiting",
        "run",
        "pixel",
        "oracle",
        "platform",
        "nse",
        "shallow",
        "associated",
        "object",
        "environment",
        "reason",
        "detail",
        "service",
        "network architecture",
        "proposed approach",
        "learning architecture",
        "achieve state",
        "conversational question",
        "present novel",
        "given question",
        "strong performance",
        "input sequence",
        "improves performance",
        "sentence level",
        "understanding tasks",
        "chinese word",
        "image classification",
        "address problem",
        "generative adversarial",
        "future research",
        "latent dirichlet",
        "dirichlet allocation",
        "address issue"]

    qa_words = [
        "question answering",
        "parameter prediction",
        "state art",
        "complex valued",
        "neural network",
        "dynamic parameter",
        "prediction network",
        "end end",
        "open domain",
        "instance segmentation",
        "convolutional neural",
        "valued network",
        "sequence data",
        "parameter layer",
        "attention mechanism",
        "domain question",
        "image question",
        "model achieve",
        "pre trained",
        "multi step",
        "recurrent unit",
        "query document",
        "document retrieval",
        "retriever reader",
        "gated recurrent",
        "deep relevance",
        "relevance ranking",
        "model human",
        "simple applications",
        "hoc document",
        "network matching",
        "quantum physics",
        "joint sequence",
        "sequence fusion",
        "multimodal sequence",
        "network consists",
        "two sequence",
        "network cnn",
        "fully connected",
        "candidate weights",
        "natural language",
        "question generation",
        "new state",
        "visual question",
        "question answer",
        "machine reading",
        "information",
        "deep learning",
        "answering dataset",
        "image captioning",
        "paper introduce",
        "art performance",
        "training",
        "based question",
        "existing",
        "tasks including",
        "cloze style",
        "comprehension task",
        "trained end",
        "language task",
        "widely used",
        "address problem",
        "proposed model",
        "sets new",
        "large number",
        "pre training",
        "new model",
        "propose",
        "passage",
        "step reasoning",
        "recurrent neural",
        "children book",
        "book test",
        "text comprehension",
        "show approach",
        "simple yet",
        "best performance",
        "art methods",
        "ensemble model",
        "task",
        "domain datasets",
        "propose end",
        "present new",
        "answer context",
        "single word",
        "multiple choice",
        "answering using",
        "language model",
        "comparable performance",
        "introduces new",
        "agnostic architecture",
        "scale corpora",
        "analysis show",
        "consistent improvement",
        "two widely",
        "models document",
        "matching model",
        "context sensitive",
        "several ways",
        "models datasets",
        "answering challenge",
        "recurrent attention",
        "structured prediction",
        "remains challenge",
        "variety applications",
        "captioning visual",
        "jointly trained",
        "competitive results",
        "cnn daily",
        "daily mail",
        "mail news",
        "well suited",
        "learning techniques",
        "alternative approaches",
        "model uses",
        "bert designed",
        "yet effective",
        "human language",
        "well designed",
        "vector space",
        "network built",
        "approach named",
        "semantic similarity",
        "language sentence",
        "data work",
        "achieves best",
        "perform multiple",
        "retrieval tasks",
        "many state",
        "problem learning",
        "set candidate",
        "using pre",
        "based baseline",
        "space word",
        "size dataset",
        "vqa task",
        "provide",
        "step retriever",
        "reader interaction",
        "interaction scalable",
        "scalable open",
        "new framework",
        "framework open",
        "answering retriever",
        "reader iteratively",
        "iteratively interact",
        "framework agnostic",
        "architecture machine",
        "reading model",
        "model requiring",
        "requiring access",
        "access token",
        "token level",
        "level hidden",
        "hidden representations",
        "representations reader",
        "retriever uses",
        "uses fast",
        "fast nearest",
        "nearest neighbor",
        "neighbor search",
        "search scale",
        "corpora containing",
        "containing millions",
        "millions paragraphs",
        "paragraphs gated",
        "unit updates",
        "updates query",
        "query step",
        "step conditioned",
        "conditioned state",
        "state reader",
        "reader reformulated",
        "reformulated query",
        "query used",
        "used rank",
        "rank paragraphs",
        "paragraphs retriever",
        "retriever conduct",
        "conduct analysis",
        "show iterative",
        "iterative interaction",
        "interaction helps",
        "helps retrieving",
        "retrieving informative",
        "informative paragraphs",
        "paragraphs corpus",
        "corpus finally",
        "finally show",
        "show multi",
        "reasoning framework",
        "framework brings",
        "brings consistent",
        "improvement applied",
        "applied two",
        "used reader",
        "reader architectures",
        "architectures drqa",
        "drqa bidaf",
        "bidaf various",
        "various large",
        "large open",
        "datasets triviaqa",
        "triviaqa unfiltered",
        "unfiltered quasart",
        "quasart searchqa",
        "searchqa squad",
        "squad open",
        "open deep",
        "ranking using",
        "using enhanced",
        "enhanced document",
        "document query",
        "query interactions",
        "interactions explore",
        "explore several",
        "several new",
        "document relevance",
        "ranking building",
        "building upon",
        "upon deep",
        "relevance matching",
        "model drmm",
        "drmm guo",
        "guo unlike",
        "unlike drmm",
        "drmm uses",
        "uses context",
        "context insensitive",
        "insensitive encodings",
        "encodings terms",
        "terms query",
        "document term",
        "term interactions",
        "interactions inject",
        "inject rich",
        "rich context",
        "sensitive encodings",
        "encodings throughout",
        "throughout models",
        "models inspired",
        "inspired pacrr",
        "pacrr hui",
        "hui convolutional",
        "convolutional gram",
        "gram matching",
        "matching features",
        "features extended",
        "extended several",
        "ways including",
        "including multiple",
        "multiple views",
        "views query",
        "document inputs",
        "inputs test",
        "test models",
        "datasets bioasq",
        "bioasq question",
        "challenge tsatsaronis",
        "tsatsaronis trec",
        "trec robust",
        "robust voorhees",
        "voorhees showing",
        "showing outperform",
        "outperform bm25",
        "bm25 based",
        "baselines drmm",
        "drmm pacrr",
        "pacrr end",
        "end instance",
        "segmentation recurrent",
        "networks gained",
        "gained impressive",
        "impressive success",
        "success recently",
        "recently solving",
        "solving structured",
        "prediction problems",
        "problems semantic",
        "semantic segmentation",
        "segmentation remains",
        "challenge differentiate",
        "differentiate individual",
        "individual object",
        "object instances",
        "instances scene",
        "scene instance",
        "segmentation important",
        "important variety",
        "applications autonomous",
        "autonomous driving",
        "driving image",
        "answering techniques",
        "techniques combine",
        "combine large",
        "large graphical",
        "graphical models",
        "models low",
        "low level",
        "level vision",
        "vision proposed",
        "proposed address",
        "end recurrent",
        "network rnn",
        "rnn architecture",
        "architecture attention",
        "mechanism model",
        "counting process",
        "process produce",
        "produce detailed",
        "detailed instance",
        "network jointly",
        "trained sequentially",
        "sequentially produce",
        "produce regions",
        "regions interest",
        "interest well",
        "well dominant",
        "dominant object",
        "object segmentation",
        "segmentation within",
        "within region",
        "achieves competitive",
        "results cvppp",
        "cvppp kitti",
        "kitti cityscapes",
        "cityscapes datasets",
        "datasets text",
        "text understanding",
        "understanding attention",
        "attention sum",
        "sum reader",
        "reader network",
        "network several",
        "several large",
        "large cloze",
        "style context",
        "context question",
        "answer datasets",
        "datasets introduced",
        "introduced recently",
        "recently cnn",
        "news data",
        "data children",
        "test thanks",
        "thanks size",
        "datasets associated",
        "associated text",
        "task well",
        "suited deep",
        "techniques currently",
        "currently seem",
        "seem outperform",
        "outperform alternative",
        "approaches present",
        "new simple",
        "simple model",
        "uses attention",
        "attention directly",
        "directly pick",
        "pick answer",
        "context opposed",
        "opposed computing",
        "computing answer",
        "answer using",
        "using blended",
        "blended representation",
        "representation words",
        "words document",
        "document usual",
        "usual similar",
        "similar models",
        "makes model",
        "model particularly",
        "particularly suitable",
        "suitable question",
        "answering problems",
        "problems answer",
        "answer single",
        "word document",
        "document ensemble",
        "models sets",
        "art evaluated",
        "evaluated datasets",
        "datasets simple",
        "applications bert",
        "bert hoc",
        "retrieval following",
        "following recent",
        "recent successes",
        "successes applying",
        "applying bert",
        "bert question",
        "answering explore",
        "explore simple",
        "applications hoc",
        "required confronting",
        "confronting challenge",
        "challenge posed",
        "posed documents",
        "documents typically",
        "typically longer",
        "longer length",
        "length input",
        "input bert",
        "designed handle",
        "handle address",
        "address issue",
        "issue applying",
        "applying inference",
        "inference sentences",
        "sentences individually",
        "individually aggregating",
        "aggregating sentence",
        "sentence scores",
        "scores produce",
        "produce document",
        "document scores",
        "scores experiments",
        "experiments trec",
        "trec microblog",
        "microblog newswire",
        "newswire test",
        "test collections",
        "collections show",
        "approach simple",
        "effective report",
        "report highest",
        "highest average",
        "average precision",
        "precision datasets",
        "datasets neural",
        "neural approaches",
        "approaches aware",
        "aware cnm",
        "cnm interpretable",
        "interpretable complex",
        "paper seeks",
        "seeks model",
        "language mathematical",
        "mathematical framework",
        "framework quantum",
        "designed mathematical",
        "mathematical formulations",
        "formulations quantum",
        "physics framework",
        "framework unifies",
        "unifies different",
        "different linguistic",
        "linguistic units",
        "units single",
        "single complex",
        "valued vector",
        "words particles",
        "particles quantum",
        "quantum states",
        "states sentences",
        "sentences mixed",
        "mixed systems",
        "systems complex",
        "built implement",
        "implement framework",
        "framework semantic",
        "semantic matching",
        "well constrained",
        "constrained complex",
        "valued components",
        "components network",
        "network admits",
        "admits interpretations",
        "interpretations explicit",
        "explicit physical",
        "physical meanings",
        "proposed complex",
        "matching cnm",
        "cnm achieves",
        "achieves comparable",
        "performances strong",
        "strong cnn",
        "cnn rnn",
        "rnn baselines",
        "baselines two",
        "two benchmarking",
        "benchmarking question",
        "datasets joint",
        "fusion model",
        "model video",
        "video question",
        "answering retrieval",
        "retrieval present",
        "present approach",
        "named jsfusion",
        "jsfusion joint",
        "measure semantic",
        "similarity pairs",
        "pairs multimodal",
        "data video",
        "video clip",
        "clip language",
        "multimodal matching",
        "matching network",
        "consists two",
        "two key",
        "key components",
        "components first",
        "first joint",
        "joint semantic",
        "semantic tensor",
        "tensor composes",
        "composes dense",
        "dense pairwise",
        "pairwise representation",
        "representation two",
        "data tensor",
        "convolutional hierarchical",
        "hierarchical decoder",
        "decoder computes",
        "computes similarity",
        "similarity score",
        "score discovering",
        "discovering hidden",
        "hidden hierarchical",
        "hierarchical matches",
        "matches two",
        "sequence modalities",
        "modules leverage",
        "leverage hierarchical",
        "hierarchical attention",
        "mechanisms learn",
        "learn promote",
        "promote well",
        "well matched",
        "matched representation",
        "representation patterns",
        "patterns prune",
        "prune misaligned",
        "misaligned ones",
        "ones bottom",
        "bottom manner",
        "manner although",
        "although jsfusion",
        "jsfusion universal",
        "universal model",
        "model applicable",
        "applicable multimodal",
        "work focuses",
        "focuses video",
        "video language",
        "including multimodal",
        "multimodal retrieval",
        "retrieval video",
        "video evaluate",
        "evaluate jsfusion",
        "jsfusion model",
        "model three",
        "three retrieval",
        "retrieval vqa",
        "tasks lsmdc",
        "lsmdc model",
        "performance reported",
        "reported far",
        "choice movie",
        "movie retrieval",
        "tasks msr",
        "msr vtt",
        "vtt dataset",
        "dataset approach",
        "approach outperforms",
        "outperforms many",
        "methods image",
        "using convolutional",
        "network dynamic",
        "prediction tackle",
        "tackle image",
        "answering imageqa",
        "imageqa problem",
        "learning convolutional",
        "cnn dynamic",
        "layer whose",
        "whose weights",
        "weights determined",
        "determined adaptively",
        "adaptively based",
        "adaptive parameter",
        "prediction employ",
        "employ separate",
        "separate parameter",
        "consists gated",
        "unit gru",
        "gru taking",
        "taking question",
        "question input",
        "input fully",
        "connected layer",
        "layer generating",
        "generating set",
        "weights output",
        "challenging construct",
        "construct parameter",
        "network large",
        "number parameters",
        "parameters fully",
        "connected dynamic",
        "layer cnn",
        "cnn reduce",
        "reduce complexity",
        "complexity problem",
        "problem incorporating",
        "incorporating hashing",
        "hashing technique",
        "technique candidate",
        "weights given",
        "given parameter",
        "network selected",
        "selected using",
        "using predefined",
        "predefined hash",
        "hash function",
        "function determine",
        "determine individual",
        "individual weights",
        "weights dynamic",
        "proposed network",
        "network joint",
        "joint network",
        "cnn imageqa",
        "imageqa parameter",
        "network trained",
        "end back",
        "back propagation",
        "propagation weights",
        "weights initialized",
        "initialized using",
        "trained cnn",
        "cnn gru",
        "proposed algorithm",
        "algorithm illustrates",
        "illustrates state",
        "performance available",
        "available public",
        "public imageqa",
        "imageqa benchmarks",
        "benchmarks multi",
        "improve",
        "knowledge",
        "transformer",
        "method",
        "generate",
        "reading comprehension",
        "system",
        "type",
        "time",
        "novel",
        "vision language",
        "art result",
        "challenging",
        "accuracy",
        "study",
        "https github",
        "previous",
        "large scale",
        "paper",
        "better",
        "generation",
        "diverse",
        "language understanding",
        "without",
        "graph",
        "article",
        "obtain",
        "answer pair",
        "compared",
        "via",
        "sequence sequence",
        "require",
        "dialogue",
        "unified",
        "ask",
        "generated",
        "user",
        "fine tuning",
        "language processing",
        "paper propose",
        "results show",
        "nlp",
        "find",
        "source",
        "setting",
        "span",
        "gain",
        "make",
        "knowledge base",
        "perform",
        "output",
        "across",
        "modeling",
        "code",
        "entailment",
        "language inference",
        "available https",
        "pretraining",
        "memory",
        "conversation",
        "language representation",
        "natural question",
        "quality",
        "original",
        "long",
        "mask",
        "future",
        "demonstrate",
        "able",
        "four",
        "wikipedia",
        "relevant",
        "agent",
        "relation",
        "allow",
        "module",
        "language modeling",
        "experimental result",
        "training data",
        "reinforcement learning",
        "aim",
        "predict",
        "research",
        "encoder",
        "traditional",
        "instead",
        "standard",
        "effectiveness",
        "classification",
        "contain",
        "towards",
        "support",
        "extraction",
        "aspect",
        "coqa",
        "embedding",
        "metric",
        "language generation",
        "machine comprehension",
        "multi modal",
        "specific",
        "small",
        "much",
        "objective",
        "supervision",
        "general",
        "concept",
        "alignment",
        "build",
        "significantly",
        "related",
        "ability",
        "making",
        "improving",
        "whether",
        "biomedical",
        "contextual",
        "absolute improvement",
        "transfer learning",
        "variety images",
        "generated question",
        "due",
        "current",
        "dollar",
        "entities",
        "analyze",
        "resource",
        "highly",
        "progress",
        "solve",
        "focus",
        "adversarial",
        "evaluating",
        "table",
        "sample",
        "automatic",
        "task specific",
        "machine translation",
        "sentiment analysis",
        "self attention",
        "cross lingual",
        "experiments show",
        "conversational question",
        "bidirectional",
        "point",
        "learned",
        "translation",
        "gpt",
        "scheme",
        "high",
        "popular",
        "correct",
        "capture",
        "lstm",
        "represent",
        "conversational",
        "rule",
        "example",
        "text classification",
        "relation extraction",
        "memory network",
        "human performance",
        "propose novel",
        "fine grained",
        "learning based",
        "order",
        "content",
        "achieved",
        "train",
        "often",
        "comprehensive",
        "apply",
        "six",
        "format",
        "combining",
        "larger",
        "non",
        "shared",
        "compare",
        "mobilebert",
        "textual",
        "extend",
        "enable",
        "ernie",
        "syntactic",
        "part",
        "develop",
        "caption",
        "fact",
        "mrc",
        "fine tuned",
        "pre train",
        "wide range",
        "real world",
        "knowledge graph",
        "biomedical text",
        "semantic parsing",
        "paper present",
        "multi hop",
        "evaluation results",
        "generating natural"
    ]

    for qa in qa_words:
        if qa in nlp_words:
            continue
        else:
            print('"' + qa + '",')
